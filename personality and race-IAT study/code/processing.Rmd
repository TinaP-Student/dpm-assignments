---
title: "Examining the relationship between the big-5 personality facets and implicit racial attitudes"
subtitle: "Data processing"
author: "Tina Puskaric"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Note
- Task

commentary
```{r}

# commentary

c("code")


```

# Dependencies

```{r}

library(tidyverse)
library(janitor)
library(stringr)
library(readr)
library(dplyr)
library(knitr)
library(openxlsx)


```

# Get data

```{r}


#data_raw_demographics
data_raw_demographics <- read_csv("../data/raw/data_raw_demographics.csv") |>
  janitor::clean_names()


#data_raw_bfi
data_raw_bfi <- read_csv("../data/raw/data_raw_bfi.csv") |>
  janitor::clean_names()

#renamed the columns and 
#sliced the first row, because of the additional columnsnames
#data_raw_iat
data_raw_iat <- read_csv("../data/raw/data_raw_iat.csv") |>
  janitor::clean_names()|>
  rename(ID = participant, block_number = block, block_required_responses = 3, trial_response = trial, trial_accuracy = 5, reaction_time = 6)|>
  slice(-1)


```

# Demographics
- Extract age and gender from the raw demographics data.
```{r}
#in wide form and renameed "sex" to "gender" (in the tasks gender is mentioned) and "unique id" to "id"
#already dropped the NA to ID, because otherwise I can't view the data and R crashes sometimes

data_a_g <- data_raw_demographics|>
  na.omit(data_raw_demographics$unique_id)|> 
  pivot_wider(names_from = variable,
              values_from = response)|>
  rename(gender = sex, ID = unique_id )
  

unique(data_a_g$age)
#to see how the gender was recorded -> only m, f or NAs
unique(data_a_g$gender)
#to see if there are duplicates, does not seem to be the case
unique(duplicated(data_a_g$ID)) 


#renamed "f" & "m" to "female" and "male" and indicated the NAs as missing
#missing data here, are not reasons for exclusion, that's why just missing
#still checked whether the age was only recorded in numbers, otherwise missing
data_age_gender <- data_a_g |> 
  mutate(gender = stringr::str_remove_all(gender, regex("\\W+")), 
         gender = case_when(gender == "f" ~ "female",
                            gender == "m" ~ "male",
                            TRUE ~ "missing"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age,
                         TRUE ~ "missing"))


# data_age <- data_age_gender |>
#   select(ID, age)
# 
# data_gender <- data_age_gender|>
#   select(ID, gender)



```

# BFI Scale

## Scale adjusting 
-  Reverse score the negatively worded items: the extroversion scale items 2, 5 and 7, conscientiousness items 2, 4 5 and 9, neuroticism items 2, 5, and 7, agreeableness 1, 3, 6, and 8, and openness items 7 and 9. 
```{r}
# only goes up to 1-6, but the 0, 7 and NA will be dealt with later
# have created lists of which items need to be reversed to keep it clearer

# agreeableness 1, 3, 6, and 8, and 
r_agreeableness <- c("bfi_a1", "bfi_a3", "bfi_a6", "bfi_a8")

# openness items 7 and 9.
r_openness <- c("bfi_o7", "bfi_o9")

# neuroticism items 2, 5, and 7,
r_neuroticism <- c("bfi_n2", "bfi_n5", "bfi_n7")

# conscientiousness items 2, 4 5 and 9, 
r_conscientiousness <- c("bfi_c2", "bfi_c4","bfi_c5", "bfi_c9")

# extroversion scale items 2, 5 and 7, 
r_extroversion <- c("bfi_e2", "bfi_e5", "bfi_e7")


#reverse the specifications with case_when
data_raw_bfi_adjusted <- data_raw_bfi |>
  rename(ID = unique_id) |> 
  mutate_at(vars(r_agreeableness, r_openness, r_neuroticism, r_conscientiousness, r_extroversion), list(~ case_when(
    . == 6 ~ 1,
    . == 5 ~ 2,
    . == 4 ~ 3,
    . == 3 ~ 4,
    . == 2 ~ 5,
    . == 1 ~ 6)))

```

### Sanity Check
- Include a sanity check that assesses whether these list of item reversals, and your implementation of them, is likely to be correct: For each subscale, create a correlation table among the items (after reversals) and check that all correlations are positive. 
 
*The correlations are all positive, so the reverse seems to have worked.*

"sc_" stands for sanity check. 

I looked at each subscales and filtered the answers by 1-6, so NA and 0 and 7 are dropped.
```{r}
#to see the exact names and how many items are required in each subscale
colnames(data_raw_bfi_adjusted)


#Agreeableness has 9 items

data_bfi_sc_agreeableness <- data_raw_bfi_adjusted |>
  select(starts_with("bfi_a")) |>
  filter_all(all_vars(. %in% 1:6)) |>
  na.omit()

cor_agreeableness <- cor(data_bfi_sc_agreeableness)


#Test how it looks when the items are not reversed! -> Conclusion: the reversion worked

# NOT_REVER_data_bfi_agreeableness <- data_raw_bfi |>
#   select(starts_with("bfi_a")) |>
#   filter_all(all_vars(. %in% 1:6)) |>
#   na.omit()
# 
# NOT_REVER_cor_agreeableness <- cor(NOT_REVER_data_bfi_agreeableness)



# Conscientiousness has 9 items
# conscientiousness<- c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9")

data_bfi_sc_conscientiousness <- data_raw_bfi_adjusted |>
  select(starts_with("bfi_c")) |>
  filter_all(all_vars(. %in% 1:6)) |>
  na.omit()

cor_conscientiousness <- cor(data_bfi_sc_conscientiousness)


# Neuroticism has 8 items
# neuroticism <- c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8")

data_bfi_sc_neuroticism <- data_raw_bfi_adjusted |>
  select(starts_with("bfi_n")) |>
  filter_all(all_vars(. %in% 1:6)) |>
  na.omit()

cor_neuroticism <- cor(data_bfi_sc_neuroticism)


# Openness has 10 items
# openness <- c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")

data_bfi_sc_openness <- data_raw_bfi_adjusted |>
  select(starts_with("bfi_o")) |>
  filter_all(all_vars(. %in% 1:6)) |>
  na.omit()

cor_openness <- cor(data_bfi_sc_openness)


# Extroversion has 8 items
# extroversion <- c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8")

data_bfi_sc_extroversion <- data_raw_bfi_adjusted |>
  select(starts_with("bfi_e")) |>
  filter_all(all_vars(. %in% 1:6)) |>
  na.omit()

cor_extroversion <- cor(data_bfi_sc_extroversion)


```



## Data quality
- Check that the item level data does not violate the logical minimum and maximum scores (1 to 6). Create an exclusion variable and set participants with impossible data to "exclude".
- Check that all participants have complete data on the BFI scales they completed. Create an exclusion variable and set participants with incomplete data to "exclude".

I made two data sets and divided the participants into the groups: A & O <- participants who only completed these two scales, and N, E and C <- participants who only completed these three scales. I put the two or three scales together because the participants should have filled in either two or three completely.

First I divide the data sets by ID and the desired scales, if the participants have on the *whole* (all items in this scale) scales just NAs, I will remove them from this data set and then include them in the other data set. 

Then I excluded all those who gave impossible answers and whether they had solved all the items, if any were missing, they were also excluded.
```{r}

#for Agreeableness and Openess -> 2 scales

data_bfi_A_O <- data_raw_bfi_adjusted |>
  select(ID, starts_with(c("bfi_a", "bfi_o"))) |>
  rowwise() |> #without rowwise, this will not work!
  filter(!if_all(-ID, is.na)) |>
  mutate(exclude_impossible = if_else(all(c_across(starts_with(c("bfi_a", "bfi_o"))) %in% 1:6),
                                      "include", "exclude")) |>
  mutate(exclude_not_completed = if_else(any(is.na(c_across(starts_with(c("bfi_a", "bfi_o"))))),
                                         "exclude", "include"))



#for Extraversion, Neuroticism and Conscientiousness -> 3 scales

data_bfi_N_E_C <- data_raw_bfi_adjusted |>
  select(ID, starts_with(c("bfi_c", "bfi_e", "bfi_n"))) |>
  rowwise() |>
  filter(!if_all(-ID, is.na)) |>
  mutate(exclude_impossible = if_else(all(c_across(starts_with(c("bfi_c", "bfi_e", "bfi_n"))) %in% 1:6),
                                      "include", "exclude")) |>
  mutate(exclude_not_completed = if_else(any(is.na(c_across(starts_with(c("bfi_c", "bfi_e", "bfi_n"))))),
                                         "exclude", "include"))

#now combine the two data sets to one again
#I have adjusted the order of the columns
data_bfi_all_5 <- full_join(data_bfi_A_O, data_bfi_N_E_C,
                            by = join_by(ID, exclude_impossible, exclude_not_completed)) |>
  select(-exclude_impossible,-exclude_not_completed,
         exclude_impossible, exclude_not_completed)



```

### Data check

I check whether all IDs have been taken into account and each ID is either in "N,E,C" or "A,O" Dataset.

179 Observations as in the non-merged set - means complete.
```{r}


merged_data <- full_join(data_bfi_A_O, data_bfi_N_E_C, by = "ID")|>
  select("ID")|>
  arrange("ID")

notmerged_data <- data_raw_bfi_adjusted|>
  select("ID")|>
  arrange("ID")


#no different data found!
differences_data1 <- setdiff(notmerged_data, merged_data)
differences_data2 <- setdiff(merged_data, notmerged_data)

#no duplicates!
maybe_duplicates <- duplicated(merged_data)


```


## Mean score
- Mean-score the subscales of the BFI scale. Each participant only got either 2 or 3 subscales. 

ms_ for MeanScore
```{r}

#It would have been more elegant with "starts_with" but unfortunately that didn't work out

#openness <- c(bfi_o1, bfi_o2, bfi_o3, bfi_o4, bfi_o5, bfi_o6, bfi_o7, bfi_o8, bfi_o9, bfi_o10)
#agreeableness <- c(bfi_a1, bfi_a2, bfi_a3, bfi_a4, bfi_a5, bfi_a6, bfi_a7, bfi_a8, bfi_a9)

data_bfi_ms_A_O <- data_bfi_A_O |>
  group_by(ID) |>
  summarize(mean_agreeableness = mean(c(bfi_a1, bfi_a2, bfi_a3, bfi_a4, bfi_a5, bfi_a6, bfi_a7, bfi_a8, bfi_a9)),
            mean_openness = mean(c(bfi_o1, bfi_o2, bfi_o3, bfi_o4, bfi_o5, bfi_o6, bfi_o7, bfi_o8, bfi_o9, bfi_o10)))

# extroversion <- c(bfi_e1, bfi_e2, bfi_e3, bfi_e4, bfi_e5, bfi_e6, bfi_e7, bfi_e8)
# neuroticism <- c(bfi_n1, bfi_n2, bfi_n3, bfi_n4, bfi_n5, bfi_n6, bfi_n7, bfi_n8)
# conscientiousness<- c(bfi_c1, bfi_c2, bfi_c3, bfi_c4, bfi_c5, bfi_c6, bfi_c7, bfi_c8, bfi_c9)

data_bfi_ms_N_E_C <- data_bfi_N_E_C |>
  group_by(ID) |>
  summarize(mean_extroversion = mean(c(bfi_e1, bfi_e2, bfi_e3, bfi_e4, bfi_e5, bfi_e6, bfi_e7, bfi_e8)),
            mean_neuroticism = mean(c(bfi_n1, bfi_n2, bfi_n3, bfi_n4, bfi_n5, bfi_n6, bfi_n7, bfi_n8)),
            mean_conscientiousness = mean(c(bfi_c1, bfi_c2, bfi_c3, bfi_c4, bfi_c5, bfi_c6, bfi_c7, bfi_c8, bfi_c9)))

#joined them together
data_bfi_meanscores <- full_join(data_bfi_ms_A_O, data_bfi_ms_N_E_C, by= "ID")

```


### Meanscore Check
 - Check that the mean scores do not violate the min and max possible score (i.e., first determine this min and max score), and revise your scoring code if it does. 

The min score can only be 1 and max score can only be 6, because the average cannot be higher or lower than the values from which it was formed. 
```{r}
#the NAs are ignored because they are handled in the further 
#I have nested two if_else with each other

check_data_bfi_meanscores <- data_bfi_meanscores |>
  mutate(bounded_correctly_a = if_else(is.na(mean_agreeableness), "ignore", 
                                         if_else(between(mean_agreeableness, left = 1, right = 6), "yes", "no")),
         bounded_correctly_O = if_else(is.na(mean_openness), "ignore", 
                                         if_else(between(mean_openness, left = 1, right = 6), "yes", "no")),
         bounded_correctly_n = if_else(is.na(mean_neuroticism), "ignore", 
                                         if_else(between(mean_neuroticism, left = 1, right = 6), "yes", "no")),
         bounded_correctly_e = if_else(is.na(mean_extroversion), "ignore", 
                                         if_else(between(mean_extroversion, left = 1, right = 6), "yes", "no")),
         bounded_correctly_c = if_else(is.na(mean_conscientiousness), "ignore", 
                                         if_else(between(mean_conscientiousness, left = 1, right = 6), "yes", "no")))


#no need to revise the code, because there are no "no" s and the observations remain at 179 
bounded_correctly_a <- count(check_data_bfi_meanscores, bounded_correctly_a)
bounded_correctly_O <- count(check_data_bfi_meanscores, bounded_correctly_O)
bounded_correctly_n <- count(check_data_bfi_meanscores, bounded_correctly_n)
bounded_correctly_e <- count(check_data_bfi_meanscores, bounded_correctly_e)
bounded_correctly_c <- count(check_data_bfi_meanscores, bounded_correctly_c)



```


# IAT Scale

## D Score
- Score the trial-level IAT data using the Greenwald "D" score: Calculate a mean RT ("mean1") for blocks 3 and 6 (one score using trials from both blocks), a mean RT ("mean2") for blocks 4 and 7 (one score using trials from both blocks), and the SD of RTs in blocks 3, 4, 6 and 7 ("SD"). To calculate D: D = (mean2 - mean1)/SD. Blocks 1, 2, and 5 are practice blocks and must be discarded. 
```{r}

#removing the practice blocks has worked
data_raw_iat_check <- data_raw_iat |>
  filter(block_number %in% c("3", "4", "6", "7"))|>
  count(block_number)

#have broken D = (mean2 - mean1)/SD the formula down to several lines
data_raw_iat_D <- data_raw_iat |>
  filter(block_number %in% c("3", "4", "6", "7"))|>
  mutate(reaction_time = as.numeric(reaction_time))|>
  group_by(ID) |>
  summarize(mean1 = mean(reaction_time[block_number %in% c("3", "6")]),
            mean2 = mean(reaction_time[block_number %in% c("4", "7")]),
            SD = sd(c(reaction_time[block_number %in% c("3", "6")],
                     reaction_time[block_number %in% c("4", "7")])),
            D = (mean2 - mean1) / SD)  |>
  ungroup()

#179 Observations, agrees with the observations of BFI! 


```

### Sanity Check
- Include a sanity check: check that all D scores are in the range -2 to +2. If not, revise your implementation of the scoring code. 
```{r}

#no need to revise the code
out_of_range_d <- data_raw_iat_D |>
  filter(D < -2 | D > 2)

```

## Exclusions
- Create an exclusion variable and set participants with incomplete trial level IAT data to "exclude". Specifically, IAT should have 120 trials on the critical test blocks (i.e., blocks 3, 4, 6 and 7). Trials on the other (practice) blocks can be discarded.
- Create an exclusion variable for IAT performance: set participants with >10% of the participants trials are < 300ms, or if their accuracy is < than 75%. Only use trials from the critical test blocks when computing these (i.e., blocks 3, 4, 6 and 7).
```{r}

# here I excluded the participants with incomplete IAT trials
data_iat_incomplete <- data_raw_iat |>
  filter(block_number %in% c("3", "4", "6", "7"))|>
  group_by(ID) |>
  summarize(total_trials = n())|>
  mutate(exclude_incomplete = if_else(total_trials == 120, "include", "exclude"))|>
  ungroup()


# here I created exclusion variables for IAT performance
data_iat_trials_exclusions <- data_raw_iat |>
  filter(block_number %in% c("3", "4", "6", "7"))|>
  mutate(reaction_time = as.numeric(reaction_time), 
         less_300 = if_else(reaction_time < 300, TRUE, FALSE), # is like counting who was faster than 300 ms
         accuracy = if_else(trial_accuracy == "correct", TRUE, FALSE)) |> #same thing for accurar answers
  group_by(ID) |>
  summarize(fast_rt = mean(less_300), #the mean of how often to fast
            average_accuracy = mean(accuracy))|>
  mutate(exclude_fast = if_else(fast_rt > 0.10, "exclude", "include"), #if more than 10% of the trials are to fast -> excluded
         exclude_accuracy = if_else(average_accuracy < 0.75, "exclude", "include"))|>
  ungroup()



#I did the codes at first separated to have a better overview
#and than merged the two code blocks to keep it more compact

# exclusion_less_300 <- data_raw_iat |>
#   filter(!block_number %in% c("1", "2", "5"))|>
#   mutate(reaction_time = as.numeric(reaction_time), 
#          less_300 = if_else(reaction_time < 300, TRUE, FALSE)) |> 
#   group_by(ID) |>
#   summarize(fast_rt = mean(less_300))|>
#   mutate(exclude1 = if_else(fast_rt > 0.10, "exclude", "include"))
# 
# 
# exclusion_accuracy <- data_raw_iat|>
#   filter(!block_number %in% c("1", "2", "5"))|>
#   mutate(accuracy = if_else(trial_accuracy == "correct", TRUE, FALSE)) |>
#   group_by(ID)|>
#   summarize(average_accuracy = mean(accuracy))|>
#   mutate(exclude2 = if_else(average_accuracy < 0.75, "exclude", "include"))



```

# Combine BFI & IAT
- Combine the demographics, BFI, and IAT data into one data frame. This data frame should be one-row-one-participant. Both the mean scored and item level BFI data should be present in the dataset.
```{r}

#ID was not as nummeric and couldnt be join at first 
#prepared the dataset to join
data_processed_iat <- data_raw_iat_D|>
  full_join(data_iat_incomplete, by = "ID")|>
  full_join(data_iat_trials_exclusions, by = "ID")|>
  mutate(ID = as.numeric(ID))

data_processed_bfi <- data_bfi_all_5|>
  full_join(data_bfi_meanscores, by = "ID")


# ultimative join 
#I have marked the people (they were not included in the dataset demographics) 
#without age or gender data as missing, it is no reason to exclude them

data_processed_before_exklusions <- data_age_gender|>
  full_join(data_processed_iat, by = "ID")|>
  full_join(data_processed_bfi, by = "ID")|>
  mutate(gender = stringr::str_remove_all(gender, regex("\\W+")), 
         gender = case_when(gender == "female" ~ "female",
                            gender == "male" ~ "male",
                            TRUE ~ "missing"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age,
                         TRUE ~ "missing"))

#now we have many more observations
    

#I chekked for duplicates --> no duplicates

# data_processed_duplicates <- data_processed_before_exklusions|>
#   count(ID) |>
#   mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include"))|>
#   select(-n)
 


```

# Master exclusions
- Create a master exclude variable from the individual exclude variables. 

I will create another variable that also removes the participants without scale data, because they come from the Demographics dataset and missing scale data is not useful --> dropping
```{r}

#excluded the participants from the demographics who have no item values 
#witrh thisd codeline in the code:
#if_all(-c(ID, age, gender), is.na) ~ "exclude", 


data_processed <- data_processed_before_exklusions|>
  mutate(exclude_participant = case_when(if_all(-c(ID, age, gender), is.na) ~ "exclude", 
                                         exclude_impossible == "exclude" ~ "exclude",
                                         exclude_not_completed == "exclude" ~ "exclude",
                                         exclude_incomplete == "exclude" ~ "exclude",
                                         exclude_fast == "exclude" ~ "exclude",
                                         exclude_accuracy == "exclude" ~ "exclude",
                                         TRUE ~ "include"))


#  Participants without age and gender are taken into account --> Check
count(data_processed, age, exclude_participant)
count(data_processed, gender, exclude_participant)




#ID: 417047 - is one of those where only age and gender are present, otherwise no other values
# if excluded --> Check
# data_processed|>
#   filter(ID == 417047)|>
#   print()

```

# Write to disk
- Save the processed data to the data/processed/ folder as "data_processed.csv". 
```{r}

# exists already
dir.create("../data/processed/", recursive = TRUE)


write_csv(data_processed, "../data/processed/data_processed.csv")


```

# Codebook 
- Create a codebook for the processed data file that explains what each variable represents.
```{r}

data_processed <- read_csv("../data/processed/data_processed.csv")


if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
  codebook_template <- data.frame(variable = colnames(data_processed)) |>
    mutate(explanation = NA)

  write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}

```



# Session info

```{r}

sessionInfo()

```


