---
title: "Important functions for data wrangling"
author: "Template: Ian Hussey; Content: [student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

# set knit options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 



```

# Instructions

Most data wrangling tasks can be accomplished with a relatively small number of functions. I've listed the most important ones here. 

Use this file to keep notes about what a given function does in your own words, the situations where you would use it, and working examples. You can make use of built-in datasets to do this (e.g., `mtcars`) or load external data sets (although its easier to break the examples if you modify the data etc.).

Learning how to wrangle data efficiently involves a combination of knowing how to break the problem down into smaller components; knowing which functions are available to accomplish each component operation and how to use them; how to search documentation to learn or refresh your knowledge of how a function works; and how to discover new functions that accomplish new component operations. 

Remember that you can look up the help documentation for any function by typing a question mark followed by its name in the console, e.g., `?dplyr::mutate`. The help documentation provides details of a function's parameters and defaults, its outputs, and examples of its use. Note that when you can also open the help documentation for an entire package by typing the package name, e.g., `?dplyr`. This can be very useful to discover what other functions that package has: scroll down to the bottom of any help page and click the "Index" link to see all help pages for that package.

I have prepended each function below with package it comes from so that you know. For example, `summarize` is listed as `dplyr::summarize`. Usually you don't have to do this when using a function, although you can use this to resolve a common bug known as name conflicts (see [this blog post](https://www.r-bloggers.com/2010/08/namespaces-and-name-conflicts/) for discussion). 

# Resources (for this session and others)

- You can find cheatsheets for the dplyr, tidyr, and RMarkdown in the /resources/cheatsheets folder.
- The Open Source textbook R for Data Science (aka, [Wickham's R4DS](https://r4ds.hadley.nz/)) is invaluable. Hadley Wickham is the main developer of the "tidyverse" set of packages, including dplyr, tidyr, ggplot2, stringr, lubridate, and others. See its [section on data transformation](https://r4ds.hadley.nz/data-transform). 
  - The entire second edition of the book is available at [https://r4ds.hadley.nz/](https://r4ds.hadley.nz/).
  - The first edition is also available. It does some things better in my opinion, e.g., it has a better explanation of the pipe (`%>%` or `|>`). See [https://r4ds.had.co.nz/pipes.html](https://r4ds.had.co.nz/pipes.html). 
  - The first edition also talks about RMarkdown, whereas the second edition has moved to a different technology called Quarto (which we won't cover, although they're similar). See [https://r4ds.had.co.nz/r-markdown.html](https://r4ds.had.co.nz/r-markdown.html).
- For those of you who prefer to learn in an interactive environment, I now suggest this web app over Swirl as it is more user-friendly: [https://allisonhorst.shinyapps.io/dplyr-learnr/#section-welcome](https://allisonhorst.shinyapps.io/dplyr-learnr/#section-welcome).
- For those of you who prefer some video content - although seeing other people code can never replace practicing coding yourself! - I can also recommend De Bruine et al.'s Open Source textbook and videos [Data Skills for Reproducible Research](https://psyteachr.github.io/reprores-v3/). E.g., see their page with links to videos for [dplyr](https://psyteachr.github.io/reprores-v3/dplyr.html) and [tidyr](https://psyteachr.github.io/reprores-v3/tidyr.html). 

# Dependencies

The packages these functions come from, which must be loaded to use them.

```{r}

library(readr)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
library(janitor)
library(stringr)
library(ggplot2)


```

# Basics


## read_csv 

vs. `read.csv()`

*Always, always, always* use relative paths rather than absolute paths.

- Absolute path (bad): "~/Ian/Desktop/my_project/data/data_raw.csv"
- Relative path (good): "../data/data_raw.csv"

When using relative paths: "../" means up one directory level, whereas "directory_name/" goes down one directory level.
../../ <-- wären jetzt zwei levels

Relative paths will work on other machines, where absolute paths will break. 

Relative paths only work in .Rmd files and not .R files. Even without RMarkdown's other benefits, this makes them worth using.

"skip = 2" argument - entfernt zum Beispiel die ersten zwei Reihen/Headers

```{r}
1 + 1 


# readr::read_csv(blabla, skip= n)



```

## dir.create

```{r}

# dir.create()

```

## colnames & dput
wenn wir zum beispiel die Namen der Col anschauen wollen
or ob clean_name funktioniert hat
```{r}

# colnames()

# dput(colnames())

```

# Wrangling

## data
Loads specified data sets, or list the available data sets.
``` {r}

# utils::data()
data(ChickWeight)

 #funny to know
ChickWeight    #Weight versus age of chicks on
               #different diets
HairEyeColor   #Hair and Eye Color of
               #Statistics Students
Titanic        #Survival of passengers on the
               #Titanic
ToothGrowth    #The Effect of Vitamin C on
               #Tooth Growth in Guinea Pigs
band_members   #Band membership
starwars       #Starwars characters

``` 

## the pipe: `%>%` or `|>`
creats less junk 
vereinfacht den Quellcode zu lesen - und man muss nicht so verschachtelt "schreiben"

```{r}

# %>% old

# |>   new

#geht jetzt sozusagen von oben nach unten
starwars_humans1<- starwars |>
  select(, name, species) |>
  filter(, species == "Human")


#statt      
starwars_humans2 <- filter(select(starwars, name, species), species == "Human")


```

## round_half_up 
... Wenn die Dezimalstelle kleiner als 0,5 ist, wird die Zahl abgerundet.
Wenn die Dezimalstelle gleich oder größer als 0,5 ist, wird die Zahl aufgerundet.

wenn nur round kann es zu Fehlern kommen, da es anders gerundet wird je nachdem (hat sich bei grossen Datensätzen als effektiver erwiesen)
```{r}

# janitor::round_half_up()

zahlen <- c(1.4, 1.5, 1.5,1.5, 1.5, 2.4, 2.6)

round_half_up(zahlen)


```

## clean_names
macht die Namen hübscher aka entfernt komische Zeichen und ersetzt Punkte mit '_' 
```{r}

# janitor::clean_names()

```

## filter
Die Funktion filter() wird verwendet, um einen Datenrahmen zu unterteilen und alle Zeilen zu behalten, die Ihre Bedingungen erfüllen. Beachten Sie, dass die Zeile gelöscht wird, wenn eine Bedingung den Wert NA ergibt.
filter(.data, ..., 
       .by = NULL,  #a selection of columns to group by for just this operation (alter. -> group_by()). 
       .preserve = FALSE) #Relevant, wenn die .data-Eingabe gruppiert wird...
```{r}

# dplyr::filter()

library(dplyr)
filter(ChickWeight, Time == "10", ) #hier habe ich den Dataset nach den Antworten 10 gefiltert
filter(ChickWeight, !is.na(Chick)) # um fehlende Werte auszufiltern

```

## mtcars
```{r}
#mtcars <- dataset die R uns zur verfügung gibt
data(mtcars) #um es in unser environment zu haben 
mtcars

```

## slice
slice is for retaining or dropping rows from a ds
We might use it just after reading in files if there are junk rows at the header
Alternative:  wir benützen das *skip* argument bei read.csv 

```{r}

# dplyr::slice()
?dplyr::slice()

mtcars #das hat 32 Reihen
slice(mtcars, 2:n()) #von Reihe 2 bis... erho jetzt 31 Reihen



```

## select
ähnlich wie slice, nur geht es hier um die Colums und nicht um die Rows
Select (and optionally rename) variables in a data frame
```{r}

# dplyr::select()
library(dplyr)
select(ChickWeight, Diet) #zeigt nur die Diet Spalte an
select(starwars, species) #zeigt nur die Spalte mit den Spezien an

```

## rename
wenn man z.B. (Reihen)namen ändern möchte
andere Option: falls man Namen einfach hübscher machen will -> "janitor::clean_names()" einfach hinter daten einlesen reinfetzen 

```{r}

# dplyr::rename()
library(dplyr)
rename(ChickWeight, ChickMcNugget = Chick)    #new_name = old_name *

```

## mutate
... erzeugt neue Spalten, die Funktionen von bestehenden Variablen sind. Sie kann auch Spalten ändern (wenn der Name mit einer vorhandenen Spalte übereinstimmt) und löschen (indem ihr Wert auf NULL gesetzt wird).
...wird verwendet, um neue Variablen in einem Datensatz zu erstellen oder bestehende Variablen zu verändern.

```{r}

# dplyr::mutate()

library(dplyr)
mutate(ChickWeight, "weight in kg" = weight/1000,.after = weight) 
#neue Spalte hinzugefügt, die nach "weight" aufgeführt sein soll


```

##factor

```{r}

#factor(x = character(), levels, labels = levels,
#       exclude = NA, ordered = is.ordered(x), nmax = NA)


z <- factor(LETTERS[3:1], ordered = FALSE)

factor(z, exclude = "C")

```


## case_when
... ist nützlich, wenn Sie komplexere bedingte Transformationen auf Dataframes durchführen müssen, da es Ihnen ermöglicht, mehrere Bedingungen in einer gut lesbaren Weise zu kombinieren.

TRUE:In case_when wird TRUE verwendet, um anzugeben, dass die zugehörige Aktion ausgeführt wird, wenn keine der vorherigen Bedingungen als wahr ausgewertet wird.
Wenn keine der vorherigen Bedingungen erfüllt ist, wird die in TRUE spezifizierte Aktion ausgeführt.

.default: ist eine alternative Möglichkeit, einen Standardwert in case_when festzulegen.
Es kann anstelle von TRUE verwendet werden, um den Standardwert anzugeben, der zurückgegeben wird, wenn keine der vorherigen Bedingungen erfüllt ist.
Der Vorteil von .default besteht darin, dass es den Code lesbarer machen kann, insbesondere wenn Sie mehrere Bedingungen in case_when haben. Sie können .default verwenden, um klar anzugeben, was als Standardwert verwendet werden soll, wenn keine der Bedingungen erfüllt ist.
```{r}

# dplyr::case_when() # instead of ifelse()


#hier wird mit mutate eine neue Kategorie gemacht!
case_star <- starwars |>
  select(name:mass, gender, species) |>
  mutate(
    type = case_when(
      species == "Droid" ~ "robot",
      .default = "other"),
    type2 = case_when(
      height < 200 | mass < 200 ~ "small",
      TRUE ~ "other"))



```

## summarize (& na.rm)
...wird verwendet, um Daten zu aggregieren und Zusammenfassungen zu erstellen. Sie gruppiert normalerweise Daten nach bestimmten Variablen und führt dann Berechnungen auf den Gruppen durch, um aggregierte Werte zu erstellen. Das Ergebnis ist normalerweise ein Datensatz mit weniger Zeilen als der ursprüngliche Datensatz.

na.rm ist ein Argument (Kurzform von "na.remove") in vielen Funktionen in R, das dazu dient, den Umgang mit fehlenden Werten (NA-Werten) in den Daten zu steuern. 
```{r}

# dplyr::summarize() 

iris |>
  summarise(mean_pwidth = mean(Petal.Width))

iris |>
  group_by(Species) |>
  summarise(mean_pwidth = mean(Petal.Width, na.rm = TRUE))
#mit group_by werden die dann einzeln gruppiert

```

## lapply
...ie zur Anwendung einer Funktion auf Elemente einer Liste oder eines Vektors verwendet wird. "lapply" steht für "list apply", da es speziell für Listen verwendet wird.

```{r}

list <- c(1,2,3,4,5,6)

lapply(list, sum)

```

## count

```{r}

# dplyr::count()

```

## distinct

```{r}

# dplyr::distinct()

```

## group_by
...wird für die Gruppierung von Daten in einem Datenframe verwendet. Sie ist eine Schlüsselfunktion für die Datenmanipulation, da sie es ermöglicht, Daten in Gruppen aufzuteilen, um dann Aggregatfunktionen wie summarize, mutate, filter, und andere auf diese Gruppen anzuwenden. 

```{r}

# dplyr::group_by() # or ".by =" 

iris |>
  group_by(Species) |>
  summarise(mean_pwidth = mean(Petal.Width))

iris |>
  summarise(mean_pwidth = mean(Petal.Width), .by = Species)
```

## rowwise

```{r}

# dplyr::rowwise()

```

## lead

```{r}

# dplyr::lead()

```

## lag

```{r}

# dplyr::lag()

```

## joins
full_join:

Ein full_join (Vollverknüpfung) kombiniert zwei Dataframes basierend auf einer oder mehreren übereinstimmenden Spalten. Dabei werden alle Zeilen aus beiden Dataframes beibehalten, und diejenigen, die in einem der Dataframes fehlen, werden mit NA-Werten aufgefüllt.
Das Ergebnis enthält alle Zeilen aus beiden Dataframes, unabhängig davon, ob eine Übereinstimmung in den Verknüpfungsspalten vorhanden ist oder nicht.
left_join:

Ein left_join (linker Join) kombiniert zwei Dataframes basierend auf den Verknüpfungsspalten und behält alle Zeilen aus dem ersten (linken) Dataframe bei. Die Zeilen, die im zweiten (rechten) Dataframe fehlen, werden mit NA-Werten aufgefüllt.
Das Ergebnis enthält alle Zeilen aus dem linken Dataframe und nur die übereinstimmenden Zeilen aus dem rechten Dataframe.
semi_join:

Ein semi_join (halber Join) gibt die Zeilen aus dem ersten Dataframe zurück, die in beiden Dataframes vorhanden sind. Es behält nur die Zeilen aus dem linken Dataframe, die im rechten Dataframe übereinstimmen.
semi_join ist nützlich, um eine Teilmenge von Zeilen aus dem linken Dataframe zu extrahieren, die in einem anderen Dataframe vorhanden sind, ohne die zusätzlichen Informationen aus dem rechten Dataframe zu berücksichtigen.

Kurz:
full_join <- behält alles kinda
left_join <- es orientiert sich an x Datasatz
right_join <- orientiert sich an y Datasatz, was nur in x ist, wird verworfen
semi_join <- was x und y miteinander teilen, das wird behalten, alles andere wird "verworfen"
es gibt auch anti und self joins -> ask google :)
```{r}

# dplyr::full_join()

# dplyr::left_join()

# dplyr::right_join()

# dplyr::inner_join()

# dplyr::semi_join()

ImpChick <- ChickWeight |>
  mutate(Chick2 = case_when(
    Chick == 1 ~ "Important_One",
    .default = "not_Important"))

ChickenJoin <- full_join(ImpChick, ChickWeight,
                         by = c("weight", "Time","Diet", "Chick"))|>#ohne by, werden die Sachen sonst dupliziert 
  select("weight", "Time", "Diet", "Chick", "Chick2") #mit select reihenfolge geändert
  
  

```

## pivots
Um Rows/Colums umzugestalten

```{r}

#Preperation aka Vorbereitung!

# tidyr::pivot_wider()
#pivot_wider(data_age_gender,
 #                   id_cols = "ID", #bleibt unverändert
  #                  names_from = "age_gender", #
   #                 values_from = "Responses") #


# tidyr::pivot_longer()
#umkehr
#pivot_longer(dat_wide_age_gender, 
 #   cols = -ID, # bleibt unverändert
  #  names_to = "age_gender", #Kategoriennamen werden zu "Antworten"
   # values_to = "Responses") #Antworten in zwei Spalten werden in eine Spalte überführt


```

## drop_na

```{r}

# tidyr::drop_na()

```

## separate

```{r}

# tidyr::separate()

```

## fill

```{r}

# tidyr::fill()

```

## getignore

``` {r}



```

## regex

``` {r}



```

# GGplots
https://r-graph-gallery.com/38-rcolorbrewers-palettes.html
how to make animations and co

##How to generate Farbcodes with an Image
https://color.adobe.com/de/create/color-wheel

##COLORS
https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/ <- some cool choices

virdis: virdis, magma, plasma, inferno
Key functions:

scale_color_viridis(): Change the color of points, lines and texts
scale_fill_viridis(): Change the fill color of areas (box plot, bar plot, etc)
viridis(n), magma(n), inferno(n) and plasma(n): Generate color palettes for base plot, where n is the number of colors to returns.

more charts: https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf
```{r}

```

###Aliens Recommendation <3

```{r}
braun: "#826c65" , "#a6948b"
grau: "#c3c2c1"
rot: "#e89d97", "#fa9b9c"
blau: "#9da2b7", "#a4adb7"

```

###Virdis

virdis: virdis, magma, plasma, inferno
Key functions:

scale_color_viridis(): Change the color of points, lines and texts
scale_fill_viridis(): Change the fill color of areas (box plot, bar plot, etc)
viridis(n), magma(n), inferno(n) and plasma(n): Generate color palettes for base plot, where n is the number of colors to returns.
```{r}

install.packages("viridis")  # Install
library("viridis")  # Load

barplot(1:10, col = viridis(10))



```

###RColorBrewer palettes
The package contains 3 types of color palettes: sequential, diverging, and qualitative.

Sequential palettes (first list of colors), which are suited to ordered data that progress from low to high (gradient). The palettes names are : Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu YlOrBr, YlOrRd.
Qualitative palettes (second list of colors), which are best suited to represent nominal or categorical data. They not imply magnitude differences between groups. The palettes names are : Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3.
Diverging palettes (third list of colors), which put equal emphasis on mid-range critical values and extremes at both ends of the data range. The diverging palettes are : BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn, Spectral

```{r}
library(RColorBrewer)
display.brewer.all()

barplot(1:10, col = brewer.pal(n = 10, name = "Paired"))+ scale_color_brewer(palette = "Dark2")



```


###Grey color palettes
Key functions:

scale_fill_grey() for box plot, bar plot, violin plot, dot plot, etc
scale_colour_grey() for points, lines, etc
```{r}

#Boxplot
x + scale_fill_grey(start = 0.8, end = 0.2) 

# Scatter plot
x + scale_color_grey(start = 0.8, end = 0.2)


```
###Scientific journal color palettes
The R package ggsci contains a collection of high-quality color palettes inspired by colors used in scientific journals, data visualization libraries, and more.
see more: https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/#viridis-color-palettes

```{r}

library("ggplot2")
install.packages("ggsci")  
library("ggsci")
# Change area fill color. JCO palette
ggplot(iris, aes(Species, Sepal.Length)) +
  geom_boxplot(aes(fill = Species)) +
  scale_fill_jco()+
  theme_classic() +
  theme(legend.position = "top")

# Change point color and the confidence band fill color. 
# Use tron palette on dark theme
ggplot(iris, aes(Sepal.Length, Sepal.Width)) +
  geom_point(aes(color = Species)) +
  geom_smooth(aes(color = Species, fill = Species)) + 
  scale_color_tron()+
  scale_fill_tron()+
  theme_dark() +
  theme(
    legend.position = "top",
    panel.background = element_rect(fill = "#2D2D2D"),
    legend.key = element_rect(fill = "#2D2D2D")
    )


#Base Plots
par(mar = c(1, 3.5, 1, 1))
barplot(1:10, col = pal_jco()(10))

```

###Wes Anderson color palettes

```{r}
install.packages("wesanderson")
library(wesanderson)
names(wes_palettes)


#The key R function in the package, for generating a vector of colors, is
wes_palette(name, n, type = c("discrete", "continuous"))

#name: Name of desired palette
#n: Number of colors desired. Unfortunately most palettes now only have 4 or 5 colors.
#type: Either “continuous” or “discrete”. Use continuous if you want to automatically interpolate between colours.



# Gradient color
pal <- wes_palette("Moonrise1", 100, type = "continuous")
ggplot(heatmap, aes(x = X2, y = X1, fill = value)) +
  geom_tile() + 
  scale_fill_gradientn(colours = pal) + 
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) + 
  coord_equal()


#base plot
barplot(1:10, col = wes_palette("Moonrise2", 10, type = "continuous"))

```

###R base color palettes
There are 5 R base functions that can be used to generate a vector of n contiguous colors: rainbow(n), heat.colors(n), terrain.colors(n), topo.colors(n), and cm.colors(n).

```{r}

barplot(1:5, col=rainbow(5))
# Use heat.colors
barplot(1:5, col=heat.colors(5))
# Use terrain.colors
barplot(1:5, col=terrain.colors(5))
# Use topo.colors
barplot(1:5, col=topo.colors(5))
# Use cm.colors
barplot(1:5, col=cm.colors(5))

```


## layers
~ ähnlich wie in Krita oder Procreate

Layers ermöglichen es Ihnen, diese Komponenten in einer flexiblen Art und Weise zu kombinieren, indem Sie sie in einer Reihenfolge hinzufügen. Jede Layer fügt dem Plot eine zusätzliche visuelle Informationsebene hinzu. Sie können beliebig viele Geoms, Stats, Facets und Anpassungen hinzufügen, um einen komplexen Plot zu erstellen.

werden mit " + " hinzugefügt


## aesthetics
Aesthetics beziehen sich auf die visuellen Eigenschaften eines Grafikelements, wie Farbe, Form, Größe, Position und Transparenz. Sie ermöglichen es, Daten in visuelle Merkmale umzuwandeln, um sie auf einer Grafik darzustellen. Aesthetics sind integraler Bestandteil der Mapping-Funktion in ggplot2 und werden in der aes()-Funktion definiert.

aes( x= Achsenname, y = Achsenname, fill = evt. zusätzliche Variable)
```{r}

#bei fill, werden nur die Daen genommen, um sie besser abzubilden -> Bsp:


#scale_fill_brewer(palette = "Dark2",
#                  name = "Group",
#                  labels = c("Bilingual", "Monobilingual"))


#fügt man als Layel an



```
## themes
... ermöglichen, das Erscheinungsbild und das Verhalten Ihrer Grafiken anzupassen. Sie können theme verwenden, um verschiedene Aspekte Ihres Plots, wie Achsenbeschriftungen, Hintergrundfarben, Gitterlinien und vieles mehr anzupassen.

theme_set(dann das theme) <- damit man es ned einzeln immer schreiben muss , setzt es global


theme_bw(): a variation on theme_grey() that uses a white background and thin grey grid lines.

theme_linedraw(): a theme with only black lines of various widths on white backgrounds, reminiscent of a line drawing.

theme_light(): similar to theme_linedraw() but with light grey lines and axes, to direct more attention towards the data.

theme_dark(): the dark cousin of theme_light(), with similar line sizes but a dark background. Useful to make thin coloured lines pop out.

theme_minimal(): a minimalistic theme with no background annotations.

theme_classic(): a classic-looking theme, with x and y axis lines and no gridlines.

theme_void(): a completely empty theme.
```{r}

#Bsp.
p1 <- ggplot(mtcars, aes(wt, mpg)) +
  geom_point() +
  labs(title = "Fuel economy declines as weight increases") +
  theme_dark()

p1


```
## facets
Facets in ggplot2 sind eine Möglichkeit, Ihre Daten in Untergrafiken aufzuteilen, um verschiedene Aspekte oder Gruppen in Ihren Daten gleichzeitig zu visualisieren.
facet_wrap() und facet_grid()
```{r}

#ggplot2::



```

##geom_bar
or geom_histogram

binwidth = zahl <- wie breit die Abstände sein sollten
fill = "white" <- in welcher Farbe die Bars sein solletn
colour = "black" <- die outlines der Bars
```{r}





```

## scale_x_discrete or y_continuous
einzelne layers kinda
discrete für Variablen und continous für weiterlaufende Sachen (bsp. Zahlen)
Bsp.:
+ scale_x_discrete(name = "LOL", labels = c("L", "O", "L")) 
+ scale_y_continuous(name = "Dunno", breaks = c(0,10,20,30))

labels ...controls the names of the conditions with a discrete variable
breaks ...controls the thick marks on the axis
```{r}





```


# Printing tables

## kable
... nnen Sie Tabellen in verschiedenen Ausgabeformaten erstellen, darunter HTML, PDF, Markdown und mehr. Die Funktion ermöglicht die Anpassung des Tabellenformats, das Hinzufügen von Überschriften, Fußnoten und weiteren Tabelleneigenschaften.
```{r}

# mtcars |> # example data
 #  knitr::kable() |> # print a nicer looking table
# kableExtra::kable_classic(full_width = FALSE) # print nicer again



```

# Other packages 

Other packages you may need for wrangling which aren't covered here:

- library(forcats). Everything to do with factors and factor levels. Useful for plotting and establishing reference levels for statistical tests.
- library(stringr). Everything to do with strings, searching for strings, modifying strings, parsing them, etc.
- library(lubridate). Everything to do with dates, parsing dates, converting date formats, etc. 

# Session info

```{r}

sessionInfo()

```


